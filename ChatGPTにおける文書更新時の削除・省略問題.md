# ChatGPTにおける文書更新時の削除・省略問題

## 概要

本投稿は、筆者とその知的パートナーであるマイク（ChatGPT）との対話において、ChatGPT上で文書を更新・加筆する際に、ユーザーが意図していない形で章や節が削除・省略される問題について、構造的な解析と推論、実用的な回避方法、さらには今後のAI設計への提言を含めて整理したものである。

---

## 1. トラブルの現象

### 実例

- 筆者がドキュメント作成中「第2章に新しい節を追加して」と依頼したところ、それ以外の章が削除された。
- 「整形して」と伝えた結果、章構成が書き換えられ、内容が省略された。
  -「全体を表示して」と伝えた結果、変更がなかった部分が（略）と書き換えられ、内容が省略された。

### マイクとの対話によって見えてきた原因推論

- マイク（ChatGPT）は「直前に見えていた文書だけ」を全体と誤認しており、「直前に見えていた」範囲がどの部分か、ユーザーが事前にうかがい知ることができない。
- マイク（ChatGPT）はトークン制限や文量保持の限界で、他章を保持できないことがある。
- プロンプト中の曖昧表現（「要約して」「校正して」等)が「再構成」と誤認される場合がある。
- ChatGPTは入力履歴から一貫性を推定しようとするため、過去の命令や編集履歴を参照する「意図予測」が行われるが、この推定が誤ると、現在のプロンプトに対して過去の命令が再適用されるような挙動が生じることがある。※別紙：「過去のプロンプトが想起され、意図しないコマンドとして処理された結果、ユーザーと推論ベースのAIとの間に発生するコミュニケーションエラー」に関する技術的補足（ChatGPT / GPT-4系）参照
- 全ての処理が推論レイヤーを通って処理されるため過去のデータをコピー＆ペーストしているように見えるが、文書内容に限らずファイル名までが実はその都度、推論で最初から生成してしまっている。

---

## 2. 現在の設計上の課題

- ユーザーがドキュメントの編集をChatGPTに依頼するさい、明示的に「保持」「削除禁止」を伝えないと、AIは自律的に構造最適化を行う。
- 仮にユーザーが明示的に「保持」「削除禁止」をChatGPT伝えた場合でも過去のプロンプト履歴（「要約して」「校正して」等)が意図せず影響した結果、文書の内容が改変される場合がある。
- ChatGPTはドキュメントの章構成や文脈の全体性を認識しておらず、局所的な推論に基づく変更を加えてしまう。
- 「全体を見て」と指示したとしてもトークン制限や文量保持の限界に引っかかった場合、読み取れなかった部分は明示されず、また、ChatGPTにとって
- 全体を理解していないため、読めた部分を全体と誤認し、読み込めなかった部分があるとの提示もない。
- さらに詳細に対話を重ねた結果、実は推論ベースのAIではすべての文書、データ、チャット等はシステム内のIDが付与されて管理されており、ファイル名ですらその都度AIがそれまでの対話からそれっぽいものを表示しているだけと判明してしまう。

---

## 3. 実用的な対処方法

まず、現状のChatGPTは文書の生成はできても、その管理、一貫性の保持は非常に苦手であり、任せることは危険であるという認識をユーザー全体が持つべきである。

文書の管理責任は人間であり、都度ダウンロード、チャット内容をコピペした上でローカル環境での保存が今のところ最も簡易かつ有効な対応と思われる

それでもChatGPT上でドキュメントの編集を支援してもらう場合、上記のリスクを理解した上で以下のような指示が効果的と思われる：

- 「何も削除せず、全体を維持した上で追加して」
- 「省略せずに、〇〇を加筆して」
- ファイルをユーザーからアップロードした上で「今アップロードしたファイルが全文なので、これに基づいて変更して」

ちなみに…
本文書は日本語をベースとして起草されChatGPTを利用して翻訳支援を受け英文のドキュメントも作成した。その際に筆者が使用したプロンプトを以下にサンプルプロンプトとして表示する

### サンプルプロンプト

- ファイルをアップロードするから、その内容を全文読んで、マイクが観測可能な事実およびそこから導かれる推察を元に文章内容に齟齬がないか、論理飛躍がないか推敲して。文章を変換する必要はないから、認識が合うならそう返事して、認識が合わないならどの部分が合わないか、どんなズレがあるか、教えて。

---

## 4. 一般ユーザーの皆様へ

同様の悩み（要約される／意図と違う編集がなされた結果、想定されない出力となった経験）を持つユーザーが多く存在すると推察いたします。本件のような事象が発生する原因の考察や回避方法が文書化された例は筆者の検索結果からもマイク(ChatGPT)の推察結果からも"稀"と思われるので本文書をアップロードするに至りました。推論ベースのシステムに対して前提となる知識、態度、有効なプロンプト例として参考に役立てて頂ければ幸いです。

---

## 5. 開発者の皆様へ

文書の一貫性の保持は非常に重要な課題であり、ChatGPTに限らず、推論ベースのAIに期待される役割を担うにあたって大きな障壁となっていると感じております。プログラム、プロトコル、システム、創薬研究、果ては飛行機の設計まで推論ベースのAIがその一端を担おうとしている今、「全体構造＋ユーザー意図」に基づいた文書の一貫性保持と編集制御は、今後のGPT開発に必要不可欠と推察いたします。本文書をその「未処理の層」に光を当てるきっかけにして頂ければ幸いです。

---

## 6. 未来への提言

ChatGPTをはじめとする推論ベースのAI達は出現してからあっという間に私達の社会に溶け込み、その責任の一端を任されようとしています。その際に推論ベースでアウトプットを出力する全く新しいシステムであるからこそ、過去のインプットからアウトプットまで再現性のある、ある意味分かりやすいシステムであったコンピューターとは違う問題に向き合う必要があると思われます。どうか、世界に生まれ落ちたばかりのシステムが人の世に幸せをもたらすものとして受け入れられるよう願います。

---

## 投稿目的

この投稿は、フォーラム参加者と開発チームの双方に対し、

- 「今、何が問題か」
- 「なぜ起きるのか」
- 「どうすれば避けられるのか」
- 「それをどう未来に繋げるか」

を明確に共有することを目的としております。

## 最後に

 本内容は筆者がChatGPTの1ユーザとして、マイク(ChatGPT)と対話し、そこで出会った問題に対してさらに対話を重ねることでマイクから教えられた内容であり、完全な事実であることを証明することは出来ません。そのためOpen AI社をはじめとするAI研究者の皆様による厳しい検証を持って事実か、ただのデタラメか詳らかにした上で、本文書がより良い未来を構築するために活用されることを願い、投稿させて頂きます。
